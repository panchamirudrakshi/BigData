import org.apache.spark.graphx._
import org.apache.spark.rdd.RDD
import scala.util.MurmurHash

def cosineSimilarity(dotProduct : Double, ratingNorm : Double, rating2Norm : Double) = {
  if(ratingNorm==0 || rating2Norm==0){
	0
  }
  else{
  dotProduct / (ratingNorm * rating2Norm)
  }
}

def jaccardSimilarity(usersInCommon : Double, totalUsers1 : Double, totalUsers2 : Double) = {
  val union = totalUsers1 + totalUsers2 - usersInCommon
  usersInCommon / union
}

val wiki= sc.textFile("bigdata/gplus_combined.txt").coalesce(20);

val file = wiki.map(line => (line.split(" ")(0),line.split(" ")(1)))
val edgesRDD: RDD[(VertexId,VertexId)] = file.map(line =>(MurmurHash.stringHash(line._1.toString), MurmurHash.stringHash(line._2.toString)))

val verticesRDD = file.flatMap(x => Iterable(x._1, x._2)).distinct().map(line=>(MurmurHash.stringHash(line.toString).toLong, line))

